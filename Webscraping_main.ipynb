{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dede1c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of pages to scrape : 2\n",
      "['APPLE iPhone 13 (Blue, 128 GB)', 'APPLE iPhone 13 (Midnight, 128 GB)', 'APPLE iPhone 13 (Green, 128 GB)', 'APPLE iPhone 14 Plus (Starlight, 128 GB)', 'APPLE iPhone 13 (Pink, 128 GB)', '', 'APPLE iPhone 14 Plus (Purple, 128 GB)', 'APPLE iPhone 14 (Blue, 128 GB)', 'APPLE iPhone 14 (Midnight, 128 GB)', 'APPLE iPhone 14 ((PRODUCT)RED, 128 GB)', 'APPLE iPhone 13 (Starlight, 256 GB)', 'APPLE iPhone 13 (Pink, 256 GB)', 'APPLE iPhone 13 (Midnight, 256 GB)', 'APPLE iPhone 14 Plus (Blue, 128 GB)', 'APPLE iPhone 11 (White, 128 GB)', 'APPLE iPhone 13 (Green, 256 GB)', 'APPLE iPhone 11 (Black, 128 GB)', 'APPLE iPhone 14 Plus ((PRODUCT)RED, 128 GB)', 'APPLE iPhone 11 (Black, 64 GB)', 'APPLE iPhone 13 (Blue, 256 GB)', 'APPLE iPhone 14 (Midnight, 256 GB)', 'APPLE iPhone 14 Pro (Space Black, 128 GB)', 'APPLE iPhone 12 (Blue, 128 GB)', 'APPLE iPhone 11 (White, 64 GB)', 'APPLE iPhone 13 (Blue, 128 GB)', 'APPLE iPhone 14 Plus (Starlight, 128 GB)', 'APPLE iPhone 13 (Midnight, 128 GB)', 'APPLE iPhone 13 (Green, 128 GB)', 'APPLE iPhone 13 (Pink, 128 GB)', 'APPLE iPhone 13 (Starlight, 128 GB)', 'APPLE iPhone 14 (Midnight, 128 GB)', 'APPLE iPhone 14 Plus (Purple, 128 GB)', 'APPLE iPhone 14 (Blue, 128 GB)', 'APPLE iPhone 14 ((PRODUCT)RED, 128 GB)', 'APPLE iPhone 14 Plus (Blue, 128 GB)', 'APPLE iPhone 13 (Starlight, 256 GB)', 'APPLE iPhone 13 (Pink, 256 GB)', 'APPLE iPhone 11 (White, 128 GB)', 'APPLE iPhone 11 (Black, 128 GB)', 'APPLE iPhone 13 (Midnight, 256 GB)', 'APPLE iPhone 14 Plus ((PRODUCT)RED, 128 GB)', 'APPLE iPhone 11 (Black, 64 GB)', 'APPLE iPhone 13 (Green, 256 GB)', 'APPLE iPhone 13 (Blue, 256 GB)', 'APPLE iPhone 12 (Blue, 128 GB)', 'APPLE iPhone 14 Pro (Space Black, 128 GB)', 'APPLE iPhone 11 (White, 64 GB)', 'APPLE iPhone 14 (Midnight, 256 GB)']\n",
      "['₹61,999', '₹61,999', '₹61,999', '₹75,999', '₹61,999', '', '₹75,999', '₹69,999', '₹69,999', '₹67,999', '₹71,999', '₹71,999', '₹71,999', '₹75,999', '₹44,999', '₹71,999', '₹44,999', '₹75,999', '₹40,999', '₹71,999', '₹79,999', '₹1,19,999', '₹56,999', '₹40,999', '₹61,999', '₹75,999', '₹61,999', '₹61,999', '₹61,999', '₹61,999', '₹69,999', '₹75,999', '₹69,999', '₹67,999', '₹75,999', '₹71,999', '₹71,999', '₹44,999', '₹44,999', '₹71,999', '₹75,999', '₹40,999', '₹71,999', '₹71,999', '₹56,999', '₹1,19,999', '₹40,999', '₹79,999']\n",
      "['4.7', '4.7', '4.7', '4.7', '4.7', '', '4.7', '4.6', '4.6', '4.6', '4.7', '4.7', '4.7', '4.7', '4.6', '4.7', '4.6', '4.7', '4.6', '4.7', '4.6', '4.7', '4.6', '4.6', '4.7', '4.7', '4.7', '4.7', '4.7', '4.7', '4.6', '4.7', '4.6', '4.6', '4.7', '4.7', '4.7', '4.6', '4.6', '4.7', '4.7', '4.6', '4.7', '4.7', '4.6', '4.7', '4.6', '4.6']\n",
      "['2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '', '9,152 Ratings\\xa0&\\xa0564 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '1,084 Ratings\\xa0&\\xa085 Reviews', '1,88,491 Ratings\\xa0&\\xa012,810 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '9,152 Ratings\\xa0&\\xa0564 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '2,05,545 Ratings\\xa0&\\xa011,035 Reviews', '1,88,491 Ratings\\xa0&\\xa012,810 Reviews', '1,084 Ratings\\xa0&\\xa085 Reviews', '1,91,862 Ratings\\xa0&\\xa011,090 Reviews', '30,261 Ratings\\xa0&\\xa01,160 Reviews']\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries \n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "#Getting the url to scrape and user-agent \n",
    "url='https://www.flipkart.com/search?q=iphone&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off'\n",
    "headers=({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36',\n",
    " 'Accept-language': 'en-US,en;q=0.5'})\n",
    "# Sending Requests to webpage to get html code \n",
    "webpage = requests.get(url,headers=headers)\n",
    "soup = BeautifulSoup(webpage.content,'html.parser')\n",
    "# To get link of the page \n",
    "clist = soup.find(\"a\",attrs={\"class\":\"ge-49M _2Kfbh8\"})\n",
    "clist1 = clist.get(\"href\")\n",
    "main_link = 'https://www.flipkart.com'\n",
    "link = main_link+clist1\n",
    "# Got the page1 link and then getting the link of 1st product of page1 \n",
    "url1 = 'https://www.flipkart.com/search?q=iphone&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=1'\n",
    "webpage1 = requests.get(url1,headers=headers)\n",
    "soup1 = BeautifulSoup(webpage1.content,'html.parser')\n",
    "product = soup1.find_all(\"a\",attrs={\"class\":\"_1fQZEK\"})\n",
    "product1= main_link+product[0].get(\"href\")\n",
    "# Creating empty lists for required contents\n",
    "products =[]\n",
    "title=[]\n",
    "price=[]\n",
    "rating=[]\n",
    "reviews=[]\n",
    "# Getting all products link from all pages which are scraped \n",
    "s = int(input(\"Enter the number of pages to scrape : \"))\n",
    "for i in range(s):\n",
    "    url1 = 'https://www.flipkart.com/search?q=iphone&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page={}'.format(i)\n",
    "    webpage1 = requests.get(url1,headers=headers)\n",
    "    soup1 = BeautifulSoup(webpage1.content,'html.parser')\n",
    "    product = soup1.find_all(\"a\",attrs={\"class\":\"_1fQZEK\"})\n",
    "    for n in product:\n",
    "        products.append(main_link+n.get(\"href\"))\n",
    "\n",
    "        \n",
    "# Making functions to Scrape the title of products \n",
    "def get_title(soup):\n",
    "\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"span\", attrs={\"class\":'B_NuCI'})\n",
    "        \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    "\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    "\n",
    "    except AttributeError: \n",
    "        title_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "\n",
    "    try:\n",
    "        price = soup.find(\"div\", attrs={'class':'_30jeq3 _16Jk6d'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find(\"div\", attrs={'class':'_3I9_wc _2p6lqe'}).string.strip()\n",
    "\n",
    "        except:\n",
    "            price = \"\"\n",
    "\n",
    "    return price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = soup.find(\"div\", attrs={'class':'_3LWZlK'}).text.strip()\n",
    "    \n",
    "#     except AttributeError:\n",
    "#         try:\n",
    "#             rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "#         except:\n",
    "#             rating = \"\"\n",
    "    except AttributeError:\n",
    "            rating = \"\"\n",
    "\n",
    "    return rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        r = soup.find(\"span\", attrs={'class':'_2_R_DZ'})\n",
    "        review_count = r.find(\"span\").text.strip()\n",
    "        \n",
    "    except AttributeError:\n",
    "  \n",
    "        review_count = \"\"\t\n",
    "\n",
    "    return review_count\n",
    "\n",
    "# Scraping the Title , Price , Rating , Reviews for all the products of pages mentioned\n",
    "for n in products:\n",
    "    url_p = n\n",
    "    headers=({'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36',\n",
    "            'Accept-language': 'en-US,en;q=0.5'})\n",
    "    webpage_p = requests.get(url_p,headers=headers)\n",
    "    soup_p = BeautifulSoup(webpage_p.content,'html.parser')\n",
    "    title.append(get_title(soup_p))\n",
    "    price.append(get_price(soup_p))\n",
    "    rating.append(get_rating(soup_p))\n",
    "    reviews.append(get_review_count(soup_p))\n",
    "    \n",
    "print(title)\n",
    "print(price)\n",
    "print(rating)\n",
    "print(reviews)\n",
    "\n",
    "df = pd.DataFrame({\"Product_name\":title,\"Price\":price,\"Rating\":rating,\"Review_count\":reviews})\n",
    "# print(df)\n",
    "df.to_csv(\"D:/KJ/Webscrape.csv\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc069081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "48\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(title))\n",
    "print(len(price))\n",
    "print(len(rating))\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c589be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721fc14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
